{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cs342 via Tensorflow Flower Project Dr. Ross October 2010 Ver 1.00**\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "Note: SuperTux is a free and open-source two-dimensional platform video game series published under the GNU General Public License. The platform was inspired by Nintendo's Super Mario Bros. series; but instead of Mario, the hero in the game is Tux, the official mascot of the Linux kernel. Wikipedia\n",
    "\n",
    "SuperTuxKart, one of the games within SuperTux series, is a free and open-source kart racing game, distributed under the terms of the GNU General Public License, version 3. It features mascots of various open-source projects. SuperTuxKart is cross-platform, running on Linux, macOS, Windows, and Android systems. Wikipedia\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "** The  original SuperTuxKart classified image training & valid database will be downloaded from University of Texas at Austin then restructured from a \n",
    "\n",
    "\n",
    "**single heterogeneus image database containing two sub-data bases, the classified training image files plus the classified valid image files along with two embedded comprehensive co-sequential corresponding csv label files** \n",
    "\n",
    "to a\n",
    "\n",
    "**single database containing 6 homogenious image sub-directories, one directory per unique label name found in the original database, with each such subdirectory being named after one of the unique label names, and containing all the sorted images associated with the unique label name given to the subdirectory.**\n",
    "\n",
    "This restructuring will effectivly render the original SuperTuxKart classified training + valid image databases into a merged conformant form identical to the tensorflow 'Flowers' Tutorial Database and thus then directly usable in the Tensorflow 'Flowers' Tutorial in lieu of the Google sourced Flowers database.\n",
    "\n",
    "The restructured database main directory will be placed on the gdrive at \n",
    "\n",
    "location /content/gdrive/My Drive/cs342/\n",
    "\n",
    "with the name of:\n",
    "\n",
    "/supertux_classified_cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\n",
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 4E94-FA53\n",
      "\n",
      " Directory of C:\\\n",
      "\n",
      "10/21/2020  07:48 PM    <DIR>          ActiveTcl\n",
      "09/04/2019  03:34 AM    <DIR>          AMD\n",
      "06/05/2015  01:49 AM               260 hcwDriverInstall.txt\n",
      "12/10/2016  10:56 PM    <DIR>          HP_Color_LaserJet_Pro_MFP_M277\n",
      "09/03/2019  07:32 AM    <DIR>          inetpub\n",
      "05/26/2019  02:44 PM    <DIR>          Keil\n",
      "05/13/2020  02:59 PM    <DIR>          PerfLogs\n",
      "10/27/2020  01:08 PM    <DIR>          Program Files\n",
      "11/06/2020  10:16 PM    <DIR>          Program Files (x86)\n",
      "06/09/2018  01:51 PM    <DIR>          Python\n",
      "01/08/2016  01:30 PM    <DIR>          Python27\n",
      "09/04/2019  03:40 AM    <DIR>          Users\n",
      "05/12/2016  12:00 AM    <DIR>          Virtual_Machines\n",
      "10/23/2020  09:45 PM    <DIR>          Windows\n",
      "05/24/2020  07:46 PM    <DIR>          ZZZ_Old_Taxes\n",
      "               1 File(s)            260 bytes\n",
      "              14 Dir(s)  165,529,227,264 bytes free\n",
      "[WinError 2] The system cannot find the file specified: 'content'\n",
      "C:\\\n",
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 4E94-FA53\n",
      "\n",
      " Directory of C:\\\n",
      "\n",
      "10/21/2020  07:48 PM    <DIR>          ActiveTcl\n",
      "09/04/2019  03:34 AM    <DIR>          AMD\n",
      "06/05/2015  01:49 AM               260 hcwDriverInstall.txt\n",
      "12/10/2016  10:56 PM    <DIR>          HP_Color_LaserJet_Pro_MFP_M277\n",
      "09/03/2019  07:32 AM    <DIR>          inetpub\n",
      "05/26/2019  02:44 PM    <DIR>          Keil\n",
      "05/13/2020  02:59 PM    <DIR>          PerfLogs\n",
      "10/27/2020  01:08 PM    <DIR>          Program Files\n",
      "11/06/2020  10:16 PM    <DIR>          Program Files (x86)\n",
      "06/09/2018  01:51 PM    <DIR>          Python\n",
      "01/08/2016  01:30 PM    <DIR>          Python27\n",
      "09/04/2019  03:40 AM    <DIR>          Users\n",
      "05/12/2016  12:00 AM    <DIR>          Virtual_Machines\n",
      "10/23/2020  09:45 PM    <DIR>          Windows\n",
      "05/24/2020  07:46 PM    <DIR>          ZZZ_Old_Taxes\n",
      "               1 File(s)            260 bytes\n",
      "              14 Dir(s)  165,529,227,264 bytes free\n"
     ]
    }
   ],
   "source": [
    "%cd /\n",
    "%ls\n",
    "%cd content\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1fbcb755af39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Note: Make sure to reset colab runtime before running a second time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "######\n",
    "# import required libraries\n",
    "#\n",
    "# Create required directories in colab root directory /\n",
    "#######\n",
    "\n",
    "\n",
    "# Note: Make sure to reset colab runtime before running a second time\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# create content directory in colab root\n",
    "%cd /\n",
    "!mkdir content\n",
    "\n",
    "# Ceate supertux sub-directory for Supertux files in content directory and make it WD\n",
    "%cd content/\n",
    "%ls\n",
    "\n",
    "!mkdir supertux\n",
    "%cd /content/supertux\n",
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Get Supertux Files (classification and segmentation data files) from UT Texas \n",
    "# CS Department into supertux WD, then unpack them into their own directory\n",
    "###############\n",
    "\n",
    "# Note: Only Classification Database will be used in this program\n",
    "\n",
    "dataset_c_url = \"https://www.cs.utexas.edu/~philkr/supertux_classification_trainval.zip\"\n",
    "\n",
    "# Note: Segmentation Database will not be used in this program\n",
    "\n",
    "dataset_s_url = \"https://www.cs.utexas.edu/~philkr/supertux_segmentation_trainval.zip\"\n",
    "\n",
    "print('Downloading supertux tar files from UT')\n",
    "\n",
    "# Download the UT zip files (they actually download as tar.gz files) into the supertux directory\n",
    "\n",
    "# Note: get_file is not able to untar these files, it must be done manually with unzip\n",
    "data_dir_c = tf.keras.utils.get_file(origin=dataset_c_url, \n",
    "                                 fname='/content/supertux/supertux_classification_trainval', \n",
    "                                 untar=True)\n",
    "data_dir_s = tf.keras.utils.get_file(origin=dataset_s_url, \n",
    "                                 fname='/content/supertux/supertux_segmentation_trainval', \n",
    "                                 untar=True)\n",
    "\n",
    "# Note: The !wget commands also works to retrive url referenced files, however, it also can not untar the files\n",
    "#!wget https://www.cs.utexas.edu/~philkr/supertux_classification_trainval.zip\n",
    "#!wget 'https'://www.cs.utexas.edu/~philkr/supertux_segmentation_trainval.zip\n",
    "\n",
    "!ls # List the downloaded files\n",
    "\n",
    "print(data_dir_c)\n",
    "print(data_dir_s)\n",
    "\n",
    "data_dir_c = pathlib.Path(data_dir_c) # what does this accomplish??\n",
    "data_dir_s = pathlib.Path(data_dir_s) # what does this accomplish??\n",
    "\n",
    "print(data_dir_c)\n",
    "print(data_dir_s)\n",
    "\n",
    "!ls\n",
    "\n",
    "# unzip supertux_c and supertux_s tar.gz files into WD (supertux directory)\n",
    "print('Unzipping Supertux tar.gz files into supertux directory ')\n",
    "!unzip -q /content/supertux/supertux_classification_trainval.tar.gz\n",
    "!unzip -q /content/supertux/supertux_segmentation_trainval.tar.gz\n",
    "\n",
    " # print working directory showing unzipped (classification) data and (segmentation) dense_data directories\n",
    "!pwd\n",
    "!ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Build a Python list (data_dir_ct_list) of the classification train (CT) jpg image \n",
    "# files contained in the classification train (CT) directory.\n",
    "####\n",
    "\n",
    "# Set Working Directory to where the classification train jpg images are located\n",
    "%cd /content/supertux/data/train/\n",
    "\n",
    "# Declare Classification Train (CT) image file list \n",
    "data_dir_ct_list = []\n",
    "\n",
    "# Fill the classifcation image list from working directory data/train\n",
    "data_dir_ct_list = glob.glob('*.jpg') # Files come back in jumbled order\n",
    "#---------------------------------------------------------------------------------\n",
    "# Note: list(pathlib.Path(\".\").rglob(\"*.jpg\")) would also fetch images into list\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "# Sort the list 00001 -> 21000\n",
    "data_dir_ct_list.sort() # sort back into ascending order\n",
    "\n",
    "# Do an image count of the classification train image file list\n",
    "image_count = len(data_dir_ct_list)\n",
    "\n",
    "                \n",
    "# Print Classification Train Image count\n",
    "print('Classification Image Train List count = ',image_count)\n",
    "\n",
    "# Print Classification Train Image List type\n",
    "print('Classification Image Train List type is = ',type(data_dir_ct_list[1]))\n",
    "\n",
    "# Do visual check of first three and last three entries in the image list\n",
    "print('\\n First 3 and last 3 images in CT Image List')\n",
    "\n",
    "print(data_dir_ct_list[0])\n",
    "print(data_dir_ct_list[1])\n",
    "print(data_dir_ct_list[2])\n",
    "print('\\n ---------------------\\n')\n",
    "print(data_dir_ct_list[image_count-3])\n",
    "print(data_dir_ct_list[image_count-2])\n",
    "print(data_dir_ct_list[image_count-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Build a Python list (data_dir_cv_list) of the classification valid (CV) jpg image \n",
    "# files contained in the classification valid (CV) directory.\n",
    "####\n",
    "\n",
    "#Set Working Directory to where the classification valid jpg images are located\n",
    "%cd /content/supertux/data/valid/\n",
    "\n",
    "# Declare Classification Valid (CV) image list\n",
    "data_dir_cv_list =[]\n",
    "\n",
    "# Fill the classification valid image list from working directory dense_data/train\n",
    "data_dir_cv_list = glob.glob('*.jpg') # Files come back in jumbled order\n",
    "#---------------------------------------------------------------------------------\n",
    "# Note: list(pathlib.Path(\".\").rglob(\"*.jpg\")) would also fetch images into list\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "# Sort the list 00001 -> 09000\n",
    "data_dir_cv_list.sort() # sort back into ascending order\n",
    "\n",
    "# Do an image count of the classification valid image list and\n",
    "# add 'cv' suffix to file name after numeric part and prior to .jpg part\n",
    "image_count = len(data_dir_cv_list)\n",
    "\n",
    "\n",
    "# Add cv suffix to image file names\n",
    "#for x in range(image_count): \n",
    "#  f_name = data_dir_cv_list[x]\n",
    "#  f_name_part = f_name.split('.')\n",
    "#  data_dir_cv_list[x] = f_name_part[0] + '_cv' + '.' + f_name_part[1]\n",
    "\n",
    "# Print Classification Valid Image count\n",
    "print('Classification Valid Image List count = ',image_count)\n",
    "\n",
    "# Print Classification Valid Image List type\n",
    "print('Segmentation Image List type is = ',type(data_dir_cv_list[1]))\n",
    "\n",
    "# Do visual check of first three and last three entries in the image list\n",
    "print('\\nFirst 3 and last 3 images in CV Image List')\n",
    "\n",
    "print(data_dir_cv_list[0])\n",
    "print(data_dir_cv_list[1])\n",
    "print(data_dir_cv_list[2])\n",
    "print('\\n ---------------------\\n')\n",
    "print(data_dir_cv_list[image_count-3])\n",
    "print(data_dir_cv_list[image_count-2])\n",
    "print(data_dir_cv_list[image_count-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Show sample classification train image\n",
    "###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Open sample classification train image with PIL\n",
    "path = r'/content/supertux/data/train/' + data_dir_ct_list[0]\n",
    "print (path)\n",
    "im = PIL.Image.open(path)\n",
    "\n",
    "#Get basic details about the image\n",
    "print(im.format)\n",
    "print(im.mode)\n",
    "print(im.size)\n",
    "\n",
    "# Show the image with PLT\n",
    "plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Show sample classifiction valid image\n",
    "###\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Open sample classification image with PIL\n",
    "path = r'/content/supertux/data/valid/' + data_dir_cv_list[0]\n",
    "print (path)\n",
    "im = PIL.Image.open(path)\n",
    "\n",
    "# Print basic details about the image\n",
    "print(im.format)\n",
    "print(im.mode)\n",
    "print(im.size)\n",
    "\n",
    "# Show the image with PLT\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Read Supertux Classification Train (CT) label File (.csv) into \n",
    "# Headers and Row Python Lists\n",
    "###\n",
    "\n",
    "# import csv module to read supertux (CT) labels cvs files\n",
    "import csv \n",
    "\n",
    "# set cwd to supertux sub folder containing classification Train labels csv file\n",
    "%cd /content/supertux/data/train/\n",
    "\n",
    "# Set filename variable to train labels .csv file name \n",
    "filename = \"labels.csv\"\n",
    "  \n",
    "# Declare the Headers and Rows lists\n",
    "# These two lists act as a crude xcel cvs spreadsheet\n",
    "\n",
    "\n",
    "# Headers will contain the Label CSV column Headers\n",
    "# (i.e. 'File','Label','Track')\n",
    "headers_ct = [] \n",
    "\n",
    "# Rows will contain the Label CSV Data Rows\n",
    "# (i.e. Image File Name, Label Name, Track Name)\n",
    "rows_ct = []    \n",
    "  \n",
    "# Read CT csv file with a cvs reader object into CT Header and CT Row Lists\n",
    "with open(filename, 'r') as csvfile: \n",
    "\n",
    "    # create a csv reader object \n",
    "    csvreader = csv.reader(csvfile) \n",
    "      \n",
    "    # extract field names (i.e. headers) from first row \n",
    "    headers_ct = next(csvreader) \n",
    "  \n",
    "    # Print total number of Columns (i.e. Headers) in Classification Train file\n",
    "    print(\"\\n\",\"Total no. of columns (i.e. Headers) in classification train file:\\n\")\n",
    "    print (len(headers_ct))\n",
    "\n",
    "    # extracting each succeeding data row one by one \n",
    "    for row in csvreader: \n",
    "        rows_ct.append(row) \n",
    "  \n",
    "# Print total number of CT rows  Note: Total number of Rows will include Header Row, Data Row count is actually one less!\n",
    "print(\"\\n\",\"Total no. of rows in classification train file not including the header row:\\n %d\"%(csvreader.line_num - 1),\"\\n\")\n",
    "  \n",
    "# Print the field names \n",
    "print('Classification Train Header names are:\\n ' + ', '.join(field for field in headers_ct)) \n",
    "  \n",
    "#  Print first 5 rows \n",
    "print('\\nFirst 5 rows are:\\n') \n",
    "for row in rows_ct[:5]: \n",
    "    # parsing each column of a row \n",
    "    for col in row: \n",
    "        print(\"%10s\"%col), \n",
    "    print('\\n') \n",
    "\n",
    "print(\"First Train Row (row [0]) = \",rows_ct[0])\n",
    "print (\"Second item of Train Column Header (headers [1]) = \", headers_ct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Read Supertux Classification Valid (CV) label File (.cvs)\n",
    "###\n",
    "\n",
    "# import csv module to read supertux (CV) labels cvs files\n",
    "import csv \n",
    "\n",
    "# set cwd to supertux sub folder containing classification Valid labels csv file\n",
    "%cd /content/supertux/data/valid/\n",
    "\n",
    "# Set filename variable to valid labels .csv file name \n",
    "filename = \"labels.csv\"\n",
    "\n",
    "# Declare the Headers and Rows lists\n",
    "# These two lists act as a crude xcel cvs spreadsheet\n",
    "\n",
    "# Headers will contain the Label CSV column Headers\n",
    "# (i.e. 'File','Label','Track')\n",
    "headers_cv = [] \n",
    "\n",
    "# Rows will contain the Label CSV Data Rows\n",
    "# (i.e. Image File Name, Label Name, Track Name)\n",
    "rows_cv = []  \n",
    "\n",
    "# Read the CV csv file with a cvs reader object into the CV Header and CV Roww Lists\n",
    "with open(filename, 'r') as csvfile: \n",
    "\n",
    "    # create csv reader object \n",
    "    csvreader = csv.reader(csvfile) \n",
    "      \n",
    "    # extract field names (i.e. headers) from first row \n",
    "    headers_cv = next(csvreader)\n",
    "\n",
    "    # Print total number of headers (Columns) in Classification Valid file\n",
    "    print(\"\\n\",\"Total no. of columns in classification valid file:\\n\")\n",
    "    print (len(headers_cv))\n",
    "  \n",
    "  \n",
    "    # extracting each succeeding data row one by one \n",
    "    for row in csvreader: \n",
    "        rows_cv.append(row) \n",
    "\n",
    "        \n",
    "   \n",
    "# Print total number of CV rows  Note: Actual Total number of Rows will include Header Row, true Data Row count is actually one less!\n",
    "print(\"\\n\",\"Total no. of rows in classification valid file not including the header row:\\n %d\"%(csvreader.line_num - 1),\"\\n\")\n",
    "  \n",
    "# Print the field names \n",
    "print('Classification Valid Field names are:\\n ' + ', '.join(field for field in headers_cv)) \n",
    "  \n",
    "#  Print first 5 rows \n",
    "print('\\nFirst 5 rows are:\\n') \n",
    "for row in rows_cv[:5]: \n",
    "    # parsing each column of a row \n",
    "    for col in row: \n",
    "        print(\"%10s\"%col), \n",
    "    print('\\n') \n",
    "\n",
    "print(\"First Valid Row (row [0]) = \",rows_cv[0])\n",
    "print (\"Second item of Valid Column Header (headers [1]) = \", headers_cv[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Create File Name Lists and Label Name Lists from the Classify Train and the\n",
    "# Classify Valid CSV Image Directories Data now in the Ct and CV Row list Tuples\n",
    "#\n",
    "# Determine Number of Unique Label Names in each list\n",
    "#\n",
    "# Determine if the set of unique names in each list is equal\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "# First create lists of all Classify Train and Classify Valid File Names and labels\n",
    "\n",
    "# Declare classify/train and classify/valid File Names, labels and Unique label Lists\n",
    "file_name_list_ct = []\n",
    "file_name_list_cv = []\n",
    "label_list_ct = []\n",
    "label_list_cv = []\n",
    "unique_label_list_ct = []\n",
    "unique_label_list_cv = []\n",
    "\n",
    "# Note: Each data row is composed of 3 element Tuples (Image File Name, Label Name and Track Name) and only the File Names and labels are desired\n",
    "\n",
    "# Extract the file name lists from the 1st element of each row tuple (index 0 ) of the train and valid data rows lists\n",
    "file_name_list_ct = [x[0] for x in rows_ct]\n",
    "file_name_list_cv = [x[0] for x in rows_cv]\n",
    "\n",
    "\n",
    "# Extract the label List from the 2nd element of each row tuple (index 1) of the train and valid data rows lists\n",
    "\n",
    "label_list_cv = [x[1] for x in rows_cv]\n",
    "label_list_ct = [x[1] for x in rows_ct]\n",
    "\n",
    "# Now determine the unique names in the labels using numpy.unique  \n",
    "import numpy as np  \n",
    "        \n",
    "# Get unique label list from train label list and print\n",
    "x = np.array(label_list_ct)\n",
    "unique_label_list_ct = np.unique(x)\n",
    "print('\\nThe number of unique labels in the train label list equals: ')\n",
    "print(len(unique_label_list_ct))\n",
    "print(\"\\nThe unique labels from the train label list are as follows: \") \n",
    "print(unique_label_list_ct)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Get unique label list from valid label list and print\n",
    "x = np.array(label_list_cv)\n",
    "unique_label_list_cv = np.unique(x)\n",
    "print('\\nThe number of unique labels in the valid label list equals: ')\n",
    "print(len(unique_label_list_cv))\n",
    "print(\"\\nThe unique labels from the valid label list are as follows: \") \n",
    "print(unique_label_list_cv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Create (make) sub-directories named for each unique label within the respective union \n",
    "# of the unique label sets.\n",
    "#\n",
    "# Note: This is the same data hirearcy format as is found in the 'Flower' Data Hirearchy\n",
    "###\n",
    "import shutil\n",
    "# First Build the Classify Data Directory Hierarchy under\n",
    "\n",
    "# Set WD to /content\n",
    "%cd /content/\n",
    "%ls\n",
    "\n",
    "# First remove old classify_data incarnation and sub_directory tree If it exists from a prior run\n",
    "shutil.rmtree('classify_data', ignore_errors=True)\n",
    "\n",
    "# Create New Classify Data Sub-Directory Incarnation\n",
    "%mkdir classify_data\n",
    "\n",
    "#Set WD to new sub-directory /classify_data\n",
    "%cd classify_data\n",
    "%ls\n",
    "\n",
    "# Create Sub_Directories Tree in WD corresponding to the 5 unique Label Names\n",
    "# Either _ct or _cv Unique Label List can be used as the generator, since they are identical\n",
    "\n",
    "# Get length of list \n",
    "length = len(unique_label_list_ct) \n",
    "\n",
    "# Iterate using while loop to make Unique label Named sub-directories\n",
    "i=0\n",
    "while i < length: \n",
    "    os.mkdir(unique_label_list_ct[i]) \n",
    "    i += 1\n",
    "\n",
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Sort Classified Train Images into sub-directories named for each unique label\n",
    "###\n",
    "\n",
    "# import os module  \n",
    "import os \n",
    "#import pathlib\n",
    "  \n",
    "# import shutil module  \n",
    "import shutil \n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Process the classified 'train' data\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Initialize first source file name\n",
    "source_file_name = file_name_list_ct[0]\n",
    "print('first source file name [0] to be used = ',source_file_name)\n",
    "\n",
    "# Initialize first destination file name\n",
    "  # First insert _ct suffix to image file source name\n",
    "  # to serve as the image destination file name\n",
    "\n",
    "f_name_part = source_file_name.split('.')\n",
    "destination_file_name = f_name_part[0] + '_ct' + '.' + f_name_part[1]\n",
    "print('first destination file name [0] to be used = ',destination_file_name)\n",
    "\n",
    "# Initalize destination directory name variable\n",
    "destination_directory_name = label_list_ct[0] + '/'\n",
    "print('\\nfirst destination directory name [0] to be used = ',destination_directory_name)\n",
    "\n",
    "# Set up source path (include the final directory but exclude file name)\n",
    "source_path = r'/content/supertux/data/train/'\n",
    "print('\\ndata source path head = ', source_path)\n",
    "\n",
    "# Set up destination path (exclude both the final directory and the file name)\n",
    "destination_path = r'/content/classify_data/'\n",
    "print('\\ndata destination path head = ',destination_path)\n",
    "\n",
    "print('\\nfull (head+tail) source path [0] = ',source_path + source_file_name)\n",
    "print('\\nfull (head+tail) data destination path [0] = ',destination_path + destination_directory_name + destination_file_name)\n",
    "\n",
    "print('\\nNow copying', len(label_list_ct),' images in the ct image file that are associated with elements of the ct file name list')\n",
    "print('into the sub-directories associated with the elements in the ct label list\\n')\n",
    "\n",
    "# List files and directories prior to copy\n",
    "print(\"\\nAt start of file copying : Starting Source Path and Destination Path\\n\") \n",
    "print(source_path + source_file_name) \n",
    "print(destination_path + destination_directory_name + destination_file_name)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Note: Cooresponding Elements in the ct label list serves as destination sub-directory names \n",
    "# while corresponding Elements in the ct file name list serves as both the source file name \n",
    "# and the destination file name\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Start of the 'train' ct file copy process loop\n",
    "print('\\nTrain (ct) file copy process loop starting\\n')\n",
    "print('\\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n')\n",
    "\n",
    "file_count = len(file_name_list_ct)\n",
    "# file_count = 5\n",
    "\n",
    "for i in range(file_count):\n",
    "   # extract source file name\n",
    "   source_file_name = file_name_list_ct[i]\n",
    "\n",
    "   # Edit ct suffix to into source file name to serve as ct image destination file name\n",
    "   # to allow differentiation from CT and CV sources in latter merged ct/cv image file\n",
    "\n",
    "   # Split source file name at the 'dot'\n",
    "   f_name_part = source_file_name.split('.')\n",
    "\n",
    "   # Build destination file name from source file name parts but insert '_ct' into destination file name\n",
    "   destination_file_name = f_name_part[0] + '_ct' + '.' + f_name_part[1]\n",
    "\n",
    "   # Extract Destination Final Directory\n",
    "   destination_directory_name = label_list_ct[i] + '/'\n",
    "\n",
    "   # Copy the image file into the appropiate sub-directory with the edited source file name\n",
    "   dest = shutil.copyfile(source_path + source_file_name, destination_path + destination_directory_name + destination_file_name) \n",
    "\n",
    "# End of the 'train' ct file copy process loop \n",
    "print('\\nTrain (ct) file copy process has completed')\n",
    " #--------------------------------------------------------------------------\n",
    "\n",
    " # List files and directories after the copy\n",
    "print(\"\\nAt completion of file copying :Ending Source Path and Destination Path = \\n\") \n",
    "print(source_path + destination_file_name) \n",
    "print(destination_path + destination_directory_name + destination_file_name)\n",
    "  \n",
    "# Print full path of the last destination \n",
    "print(\"\\nFinal Destination path:\\n\", dest) \n",
    "\n",
    "dest_dir = os.path.dirname(dest)\n",
    "print(\"\\nFinal Destination directory path:\\n\", dest_dir, \"\\n\")\n",
    "\n",
    "# Count items (images) in each labeled directory\n",
    "dir_count = len(unique_label_list_ct)\n",
    "# dir_count = 5\n",
    "\n",
    "for i in range(dir_count):\n",
    "   directory_name = unique_label_list_ct[i] + '/'\n",
    "   image_folder_path = destination_path + directory_name\n",
    "   print('images in directory = ',unique_label_list_ct[i])\n",
    "   dirListing = os.listdir(image_folder_path)\n",
    "   print(len(dirListing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Sort the Classified Valid Images into the sub-directories named for each unique label\n",
    "###\n",
    "\n",
    "# import os module  \n",
    "import os \n",
    "#import pathlib\n",
    "  \n",
    "# import shutil module  \n",
    "import shutil \n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Process the classified 'valid' data (merging into existing processed classified 'train' data)\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Initialize first source file name\n",
    "source_file_name = file_name_list_cv[0]\n",
    "print('first source file name [0] to be used = ',source_file_name)\n",
    "\n",
    "# Initialize first destination file name\n",
    "  # First insert _cv suffix into image file source name\n",
    "  # to serve as the image destination file name\n",
    "\n",
    "f_name_part = source_file_name.split('.') # split at the 'dot'\n",
    "destination_file_name = f_name_part[0] + '_cv' + '.' + f_name_part[1]\n",
    "print('first destination file name [0] to be used = ',destination_file_name)\n",
    "\n",
    "# Initalize destination directory name variable\n",
    "destination_directory_name = label_list_cv[0] + '/'\n",
    "print('\\nfirst destination directory name [0] to be used = ',destination_directory_name)\n",
    "\n",
    "# Set up source path (include final directory but exclude file name)\n",
    "source_path = r'/content/supertux/data/valid/'\n",
    "print('\\ndata source path head = ', source_path)\n",
    "\n",
    "# Set up destination path (exclude final directory and exclude file name)\n",
    "destination_path = r'/content/classify_data/'\n",
    "print('\\ndata destination path head = ',destination_path)\n",
    "\n",
    "print('\\nfull (head+tail) source path [0] = ',source_path + source_file_name)\n",
    "print('\\nfull (head+tail) data destination path [0] = ',destination_path + destination_directory_name + destination_file_name)\n",
    "\n",
    "print('\\nNow copying', len(label_list_cv),' images in the cv image file that are associated with elements of the cv file name list')\n",
    "print('into the sub-directories associated with the elements in the cv label list\\n')\n",
    "\n",
    "# List files and directories prior to copy\n",
    "print(\"\\nAt start of file copying : Starting Source Path and Destination Path\\n\") \n",
    "print(source_path + destination_file_name) \n",
    "print(destination_path + destination_directory_name + destination_file_name)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Note: Cooresponding Elements in the cv label list serves as destination sub-directory names \n",
    "# while corresponding Elements in the cv file name list serves as both the source file name \n",
    "# and the destination file name\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Start of the 'valid' cv file copy process loop\n",
    "print('\\nTrain (cv) file copy process loop starting\\n')\n",
    "print('\\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n')\n",
    "\n",
    "file_count = len(file_name_list_cv)\n",
    "# file_count = 5\n",
    "\n",
    "for i in range(file_count):\n",
    "   # extract source file name\n",
    "   source_file_name = file_name_list_cv[i]\n",
    "\n",
    "   # Edit cv suffix to into source file name to serve as cv image destination file name\n",
    "   # to allow differentiation from CT and CV sources in latter merged ct/cv image file\n",
    "\n",
    "   # Split source file name at the 'dot'\n",
    "   f_name_part = source_file_name.split('.')\n",
    "\n",
    "   # Build destination file name from source file name parts but insert '_cv' into destination file name\n",
    "   destination_file_name = f_name_part[0] + '_cv' + '.' + f_name_part[1]\n",
    "\n",
    "   # Extract Destination Final Directory\n",
    "   destination_directory_name = label_list_cv[i] + '/'\n",
    "\n",
    "   # Copy the image file into the appropiate sub-directory with the edited source file name\n",
    "   dest = shutil.copyfile(source_path + source_file_name, destination_path + destination_directory_name + destination_file_name)  \n",
    "\n",
    "# End of the 'train' ct file copy process loop \n",
    "print('\\nTrain (ct) file copy process has completed')\n",
    " #--------------------------------------------------------------------------\n",
    "\n",
    " # List files and directories after the copy\n",
    "print(\"\\nAt completion of file copying :Ending Source Path and Destination Path = \\n\") \n",
    "print(source_path + source_file_name) \n",
    "print(destination_path + destination_directory_name + destination_file_name)\n",
    "  \n",
    "# Print full path of the last destination\n",
    "print(\"\\nFinal Destination path:\\n\", dest) \n",
    "\n",
    "dest_dir = os.path.dirname(dest)\n",
    "print(\"\\nFinal Destination directory path:\\n\", dest_dir, \"\\n\")\n",
    "\n",
    "# Count items (images) in each labeled directory\n",
    "dir_count = len(unique_label_list_cv)\n",
    "# dir_count = 5\n",
    "\n",
    "for i in range(dir_count):\n",
    "   directory_name = unique_label_list_cv[i] + '/'\n",
    "   image_folder_path = destination_path + directory_name\n",
    "   print('images in directory = ',unique_label_list_cv[i])\n",
    "   dirListing = os.listdir(image_folder_path)\n",
    "   print(len(dirListing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import and mount the user's google drive (gdrive) to this colab project\n",
    "\n",
    "Note: This will trigger a colab security authorization procedure\n",
    "\n",
    "As a first step colab will issue user a ULR to user's Google Chrome Account\n",
    "\n",
    "Once user is in chrome the user must authorize access to the gdrive\n",
    "\n",
    "at that point an access code will be issued\n",
    "\n",
    "Now copy this code back into the colab input request box. \n",
    "\n",
    "The user gdrive (aka My Drive) will then mount at directory location /content/gdrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be safe, verify the gdrive mounted sucessfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/gdrive/My Drive/\n",
    "\n",
    "%ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "%ls\n",
    "\n",
    "%cd /content/classify_data/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now copy the newly created & sorted \"classify_data' directory and the labeled \n",
    "\n",
    "sub-directories ( /content/classify_data/ from colab to the gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "%cd /content/\n",
    "%ls\n",
    "\n",
    "%cd /content/classify_data\n",
    "%ls\n",
    "\n",
    "source_tree = r'/content/classify_data'\n",
    "print('Source tree = ',source_tree)\n",
    "\n",
    "destination_tree = r'/content/gdrive/My Drive/supertux_classify_merged_ct+cv'\n",
    "print('Destination Tree = ',destination_tree)\n",
    "\n",
    "shutil.copytree(source_tree, destination_tree)\n",
    "\n",
    "print('Classify_Data directory (with Flower Data Sub-Directory Label Structure) has been sucessfully')\n",
    "print('copied to the gdrive My Drive directory location as a sub-directory')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
